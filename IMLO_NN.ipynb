{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Se1towo/IMLO_Exam/blob/main/IMLO_NN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qVyaU70W1PFs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b457bf5e-22a0-4d1b-db6c-cfe51477c94e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torchvision\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision.transforms import ToTensor, Lambda\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.io\n",
        "import csv\n",
        "import os\n",
        "import copy\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "!pip install torchinfo\n",
        "from tqdm import tqdm\n",
        "from torchinfo import summary"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "#torch.use_deterministic_algorithms(True)\n",
        "\n",
        "def set_seeds(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU.\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    # # Ensuring deterministic behavior in cuDNN operations\n",
        "    # torch.backends.cudnn.deterministic = True\n",
        "    # torch.backends.cudnn.benchmark = False\n",
        "    print(f\"Using seed: {seed}\")\n",
        "\n",
        "seed = random.randint(0, 2**32 - 1)\n",
        "set_seeds(seed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-_ggqpbjsc2",
        "outputId": "6ad0a988-8f03-42e2-9f0c-d287e7bda60c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using seed: 3801100149\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.style.use('ggplot')\n",
        "\n",
        "if not os.path.exists(\"outputs\"):\n",
        "    os.makedirs(\"outputs\")\n",
        "\n",
        "# Initialize early stopping parameters\n",
        "best_loss = float('inf')\n",
        "patience = 10\n",
        "\n",
        "\n",
        "class SaveBestModel:\n",
        "    \"\"\"\n",
        "    Class to save the best model while training. If the current epoch's\n",
        "    validation loss is less than the previous least less, then save the\n",
        "    model state.\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self, best_valid_loss=float('inf')\n",
        "    ):\n",
        "        self.best_valid_loss = best_valid_loss\n",
        "\n",
        "    def __call__(\n",
        "        self, current_valid_loss,\n",
        "        epoch, model, optimizer, loss_fn\n",
        "    ):\n",
        "        if current_valid_loss < self.best_valid_loss:\n",
        "            self.best_valid_loss = current_valid_loss\n",
        "            print(f\"\\nBest validation loss: {self.best_valid_loss}\")\n",
        "            print(f\"\\nSaving best model for epoch: {epoch+1}\\n\")\n",
        "            torch.save({\n",
        "                'epoch': epoch+1,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'loss': loss_fn,\n",
        "                }, 'outputs/best_model.pth')"
      ],
      "metadata": {
        "id": "zYYMnjhTCrDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_model(epochs, model, optimizer, criterion):\n",
        "    \"\"\"\n",
        "    Function to save the trained model to disk.\n",
        "    \"\"\"\n",
        "    print(f\"Saving final model...\")\n",
        "    torch.save({\n",
        "                'epoch': epochs,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'loss': criterion,\n",
        "                }, 'outputs/final_model.pth')"
      ],
      "metadata": {
        "id": "t7VmeY62CvmD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_plots(train_acc, valid_acc, train_loss, valid_loss):\n",
        "    \"\"\"\n",
        "    Function to save the loss and accuracy plots to disk.\n",
        "    \"\"\"\n",
        "    # accuracy plots\n",
        "    plt.figure(figsize=(10, 7))\n",
        "    plt.plot(\n",
        "        train_acc, color='green', linestyle='-',\n",
        "        label='train accuracy'\n",
        "    )\n",
        "    plt.plot(\n",
        "        valid_acc, color='blue', linestyle='-',\n",
        "        label='validataion accuracy'\n",
        "    )\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.savefig('outputs/accuracy.png')\n",
        "\n",
        "    # loss plots\n",
        "    plt.figure(figsize=(10, 7))\n",
        "    plt.plot(\n",
        "        train_loss, color='orange', linestyle='-',\n",
        "        label='train loss'\n",
        "    )\n",
        "    plt.plot(\n",
        "        valid_loss, color='red', linestyle='-',\n",
        "        label='validataion loss'\n",
        "    )\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.savefig('outputs/loss.png')"
      ],
      "metadata": {
        "id": "2RKNHw5XCyhH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((150,150)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "train_resize_crop = transforms.Compose([transforms.RandomResizedCrop(150), transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
        "train_center_crop = transforms.Compose([transforms.CenterCrop(100), transforms.Resize((150,150)), transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
        "train_h_flip = transforms.Compose([transforms.RandomHorizontalFlip(), transforms.Resize((150,150)), transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
        "train_v_flip = transforms.Compose([transforms.RandomVerticalFlip(), transforms.Resize((150,150)), transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
        "train_grayscale = transforms.Compose([transforms.RandomGrayscale(p=0.1), transforms.Resize((150,150)), transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
        "train_colorjitter = transforms.Compose([transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2), transforms.Resize((150,150)), transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
        "train_perspective = transforms.Compose([transforms.RandomPerspective(distortion_scale=0.5, p=0.5), transforms.Resize((150,150)), transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
        "train_rotation = transforms.Compose([transforms.RandomRotation(45), transforms.Resize((150,150)), transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
        "train_blur = transforms.Compose([transforms.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5)), transforms.Resize((150,150)), transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])"
      ],
      "metadata": {
        "id": "F0bJJe9S1UuK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plain_set = datasets.Flowers102(\n",
        "    root=\"data\",\n",
        "    split=\"train\",\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")\n",
        "print(\"Training data:\", plain_set)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GxGJ7X31cft",
        "outputId": "e16cdab9-ccfd-4c75-b350-14b99d269194"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/102flowers.tgz to data/flowers-102/102flowers.tgz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 71%|███████   | 244645888/344862509 [00:08<00:03, 31698900.10it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rc_set = datasets.Flowers102(root=\"data\",split=\"train\", download=True,\n",
        "    transform=train_resize_crop)\n",
        "cc_set = datasets.Flowers102(root=\"data\",split=\"train\", download=True,\n",
        "    transform=train_center_crop)\n",
        "hf_set = datasets.Flowers102(root=\"data\",split=\"train\", download=True,\n",
        "    transform=train_h_flip)\n",
        "vf_set = datasets.Flowers102(root=\"data\",split=\"train\", download=True,\n",
        "    transform=train_v_flip)\n",
        "gs_set = datasets.Flowers102(root=\"data\",split=\"train\", download=True,\n",
        "    transform=train_grayscale)\n",
        "cj_set = datasets.Flowers102(root=\"data\",split=\"train\", download=True,\n",
        "    transform=train_colorjitter)\n",
        "ps_set = datasets.Flowers102(root=\"data\",split=\"train\", download=True,\n",
        "    transform=train_perspective)\n",
        "rt_set = datasets.Flowers102(root=\"data\",split=\"train\", download=True,\n",
        "    transform=train_rotation)\n",
        "br_set = datasets.Flowers102(root=\"data\",split=\"train\", download=True,\n",
        "    transform=train_blur)\n",
        "\n",
        "training_data = torch.utils.data.ConcatDataset([rc_set, cc_set, hf_set, vf_set, gs_set, cj_set, ps_set, rt_set, br_set, plain_set,\n",
        "                                                hf_set, vf_set, gs_set,])\n",
        "print(\"Training data:\", training_data)"
      ],
      "metadata": {
        "id": "7pHehsP1do3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = datasets.Flowers102(\n",
        "    root=\"data\",\n",
        "    split=\"test\",\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")\n",
        "print(\"Testing data:\", test_data)\n",
        "\n",
        "validation_data = datasets.Flowers102(\n",
        "    root=\"data\",\n",
        "    split=\"val\",\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")\n",
        "print(\"Validation data:\", validation_data)"
      ],
      "metadata": {
        "id": "kYBONw1Gdlda"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 1e-4 #maybe decrease though\n",
        "batch_size = 64\n",
        "epochs = 100"
      ],
      "metadata": {
        "id": "AyCSTcbcC0ia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(training_data, batch_size, shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size, shuffle=True)\n",
        "validation_dataloader = DataLoader(validation_data, batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "lWzeP1XvDaMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset_size = len(training_data)"
      ],
      "metadata": {
        "id": "sWh4loQ5Dhh1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 9 sample images from training dataset\n",
        "labels_map = {}\n",
        "figure = plt.figure(figsize=(8, 8))\n",
        "cols, rows = 3, 3\n",
        "for i in range(1, cols * rows + 1):\n",
        "    sample_idx = torch.randint(len(training_data), size=(1,)).item()\n",
        "    img, label = training_data[sample_idx]\n",
        "    if label not in labels_map:\n",
        "      labels_map[label] = img\n",
        "    figure.add_subplot(rows, cols, i)\n",
        "    plt.title(list(labels_map.keys())[i % len(labels_map)]) #works when rerun\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(img.squeeze().T)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0nYcDWDH1jNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example training image\n",
        "train_features, train_labels = next(iter(train_dataloader))\n",
        "print(f\"Feature batch shape: {train_features.size()}\")\n",
        "print(f\"Labels batch shape: {train_labels.size()}\")\n",
        "img = train_features[0].T.squeeze()\n",
        "label = train_labels[0]\n",
        "plt.imshow(img)\n",
        "plt.show()\n",
        "print(f\"Label: {label}\")"
      ],
      "metadata": {
        "id": "dltD24X91gp1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")"
      ],
      "metadata": {
        "id": "8o8F1sZyD8SP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import torch.nn.functional as F\n",
        "\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv_pooling_stack = nn.Sequential(\n",
        "            # Convolutional Layer\n",
        "            nn.Conv2d(in_channels=3, out_channels=20, kernel_size=3, padding=1),\n",
        "            # Batch Normalization\n",
        "            nn.BatchNorm2d(20),\n",
        "            # Activation Layer\n",
        "            nn.ReLU(inplace=True),\n",
        "            # Pooling Layer\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "\n",
        "            nn.Conv2d(20, 40, kernel_size=5, padding=1),\n",
        "            # Batch Normalization\n",
        "            nn.BatchNorm2d(40),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "\n",
        "            nn.Conv2d(40, 80, kernel_size=3, padding=1),\n",
        "            # Batch Normalization\n",
        "            nn.BatchNorm2d(80),\n",
        "            nn.LeakyReLU(inplace=True),\n",
        "\n",
        "            # nn.Conv2d(80, 80, kernel_size=3, padding=1),\n",
        "            # Batch Normalization\n",
        "            # nn.BatchNorm2d(80),\n",
        "            # nn.LeakyReLU(inplace=True),\n",
        "\n",
        "            # nn.Conv2d(80, 80, kernel_size=3, padding=1),\n",
        "            # # Batch Normalization\n",
        "            # nn.BatchNorm2d(80),\n",
        "            # nn.LeakyReLU(inplace=True),\n",
        "            # nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "\n",
        "            nn.Conv2d(80, 80, kernel_size=3, padding=1),\n",
        "            # Batch Normalization\n",
        "            nn.BatchNorm2d(80),\n",
        "            nn.LeakyReLU(inplace=True),\n",
        "\n",
        "            nn.Conv2d(80, 40, kernel_size=3, padding=1),\n",
        "            # Batch Normalization\n",
        "            nn.BatchNorm2d(40),\n",
        "            nn.LeakyReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "        )\n",
        "\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            # Fully connected layers\n",
        "            nn.Linear(11560, 4096),\n",
        "            nn.LeakyReLU(inplace=True),\n",
        "            # Regularization\n",
        "            nn.Dropout(0.55),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.LeakyReLU(inplace=True),\n",
        "            # Regularization\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(4096, 102),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_pooling_stack(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.linear_relu_stack(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "lwAbUAlwD-rm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNetwork().to(device)\n",
        "# print(model)\n",
        "print(f\"Summary:\\n{summary(model, input_size=(batch_size, 3, 150, 150))}\")"
      ],
      "metadata": {
        "id": "gD7CFrx3EBlw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Model structure: {model}\\n\\n\")\n",
        "\n",
        "for name, param in model.named_parameters():\n",
        "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
      ],
      "metadata": {
        "id": "n9ChJOkuEGNt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    # Set the model to training mode\n",
        "    model.train()\n",
        "    correct = 0\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X = X.to(device)\n",
        "        y = y.to(device)\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Compute training accuracy\n",
        "        correct += (pred.argmax(1) == y).sum().item()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * batch_size + len(X)\n",
        "            print(f\"Training loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "    train_accuracy = 100.0 * correct / size\n",
        "    print(f\"Training Accuracy: {train_accuracy:.2f}%\\n\")\n",
        "    return loss, train_accuracy\n",
        "\n",
        "\n",
        "def val_loop(dataloader, model, loss_fn):\n",
        "    model.eval()\n",
        "    size = len(dataloader.dataset)\n",
        "    val_loss, correct = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X = X.to(device)\n",
        "            y = y.to(device)\n",
        "            pred = model(X)\n",
        "            val_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).sum().item()\n",
        "\n",
        "    val_loss /= batch_size\n",
        "    val_accuracy = 100.0 * correct / size\n",
        "    print(f\"Validation Error: \\n Accuracy: {val_accuracy:>0.2f}%, Validation loss: {val_loss:>8f} \\n\")\n",
        "    return val_loss, val_accuracy"
      ],
      "metadata": {
        "id": "uolSt8zUEflN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-3)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3)\n",
        "save_best_model = SaveBestModel()\n",
        "\n",
        "# lists to keep track of losses and accuracies\n",
        "train_l, valid_l = [], []\n",
        "train_acc, valid_acc = [], []\n",
        "\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loss, train_accuracy = train_loop(train_dataloader, model, loss_fn, optimizer)\n",
        "    valid_loss, val_accuracy = val_loop(test_dataloader, model, loss_fn)\n",
        "\n",
        "    # save the best model till now if we have the least loss in the current epoch\n",
        "    save_best_model(valid_loss, t, model, optimizer, loss_fn)\n",
        "    train_l.append(train_loss.cpu().detach().numpy())\n",
        "    valid_l.append(valid_loss)\n",
        "    train_acc.append(train_accuracy)\n",
        "    valid_acc.append(val_accuracy)\n",
        "\n",
        "    # Scheduler learning rate mitigation\n",
        "    scheduler.step(valid_loss)\n",
        "\n",
        "    # Early stopping\n",
        "    if valid_loss < best_loss:\n",
        "        best_loss = valid_loss\n",
        "        best_model_weights = copy.deepcopy(model.state_dict())  # Deep copy here\n",
        "        patience = 10  # Reset patience counter\n",
        "    else:\n",
        "        patience -= 1\n",
        "        if patience == 0:\n",
        "            print(\"Early stopping triggered!\")\n",
        "            break\n",
        "\n",
        "# save the trained model weights for a final time\n",
        "save_model(epochs, model, optimizer, loss_fn)\n",
        "# save the loss and accuracy plots\n",
        "save_plots(train_acc, valid_acc, train_l, valid_l)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "id": "tQlg2QSQEhxf",
        "outputId": "188283c7-de1d-40b8-dc77-0ee82a6fc208",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "Training loss: 4.689882  [   64/13260]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing best model\n",
        "\n",
        "# build the model, no need to load the pre-trained weights or fine-tune layers\n",
        "model = NeuralNetwork().to(device)\n",
        "# load the best model checkpoint\n",
        "best_model_cp = torch.load('outputs/best_model.pth')\n",
        "best_model_epoch = best_model_cp['epoch']\n",
        "print(f\"Best model was saved at {best_model_epoch} epochs\\n\")\n",
        "# load the last model checkpoint\n",
        "last_model_cp = torch.load('outputs/final_model.pth')\n",
        "last_model_epoch = last_model_cp['epoch']\n",
        "print(f\"Last model was saved at {last_model_epoch} epochs\\n\")\n",
        "\n",
        "# get the test dataset and the test data loader\n",
        "#Training\n",
        "training_data = datasets.Flowers102(root=\"data\",split=\"train\",download=True,\n",
        "    transform=transform\n",
        ")\n",
        "rc_set = datasets.Flowers102(root=\"data\",split=\"train\", download=True,\n",
        "    transform=train_resize_crop)\n",
        "cc_set = datasets.Flowers102(root=\"data\",split=\"train\", download=True,\n",
        "    transform=train_center_crop)\n",
        "hf_set = datasets.Flowers102(root=\"data\",split=\"train\", download=True,\n",
        "    transform=train_h_flip)\n",
        "vf_set = datasets.Flowers102(root=\"data\",split=\"train\", download=True,\n",
        "    transform=train_v_flip)\n",
        "gs_set = datasets.Flowers102(root=\"data\",split=\"train\", download=True,\n",
        "    transform=train_grayscale)\n",
        "cj_set = datasets.Flowers102(root=\"data\",split=\"train\", download=True,\n",
        "    transform=train_colorjitter)\n",
        "ps_set = datasets.Flowers102(root=\"data\",split=\"train\", download=True,\n",
        "    transform=train_perspective)\n",
        "rt_set = datasets.Flowers102(root=\"data\",split=\"train\", download=True,\n",
        "    transform=train_rotation)\n",
        "br_set = datasets.Flowers102(root=\"data\",split=\"train\", download=True,\n",
        "    transform=train_blur)\n",
        "training_data = torch.utils.data.ConcatDataset([rc_set, cc_set, hf_set, vf_set, gs_set, cj_set, ps_set, rt_set, br_set, plain_set])\n",
        "\n",
        "#Test and validation\n",
        "test_data = datasets.Flowers102(\n",
        "    root=\"data\",\n",
        "    split=\"test\",\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "validation_data = datasets.Flowers102(\n",
        "    root=\"data\",\n",
        "    split=\"val\",\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")\n",
        "train_dataloader = DataLoader(training_data, batch_size, shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size, shuffle=True)\n",
        "validation_dataloader = DataLoader(validation_data, batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "9tBQAI6xFkFK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo\n",
        "from tqdm import tqdm\n",
        "from torchinfo import summary\n",
        "def test(model, testloader):\n",
        "    \"\"\"\n",
        "    Function to test the model\n",
        "    \"\"\"\n",
        "    # set model to evaluation mode\n",
        "    model.eval()\n",
        "    print('Testing')\n",
        "    valid_running_correct = 0\n",
        "    counter = 0\n",
        "    with torch.no_grad():\n",
        "        for i, data in tqdm(enumerate(testloader), total=len(testloader)):\n",
        "            counter += 1\n",
        "\n",
        "            image, labels = data\n",
        "            image = image.to(device)\n",
        "            labels = labels.to(device)\n",
        "            # forward pass\n",
        "            outputs = model(image)\n",
        "            # calculate the accuracy\n",
        "            _, preds = torch.max(outputs.data, 1)\n",
        "            valid_running_correct += (preds == labels).sum().item()\n",
        "\n",
        "    # loss and accuracy for the complete epoch\n",
        "    final_acc = 100. * (valid_running_correct / len(testloader.dataset))\n",
        "    return final_acc\n",
        "\n",
        "# test the last epoch saved model\n",
        "def test_last_model(model, checkpoint, test_loader):\n",
        "    print('Loading last epoch saved model weights...')\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    test_acc = test(model, test_loader)\n",
        "    print(f\"Summary: {summary(model, input_size=(batch_size, 3, 150, 150))}\")\n",
        "    print(f\"Last epoch saved model accuracy: {test_acc:.3f}\\n\")\n",
        "# test the best epoch saved model\n",
        "def test_best_model(model, checkpoint, test_loader):\n",
        "    print('Loading best epoch saved model weights...')\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    test_acc = test(model, test_loader)\n",
        "    print(f\"Summary: {summary(model, input_size=(batch_size, 3, 150, 150))}\")\n",
        "    print(f\"Best epoch saved model accuracy: {test_acc:.3f}\")"
      ],
      "metadata": {
        "id": "XEMht6hlF-s3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_last_model(model, last_model_cp, test_dataloader)\n",
        "test_best_model(model, best_model_cp, test_dataloader)"
      ],
      "metadata": {
        "id": "IUxMaeAoGI1t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions for 9 sample images from testing dataset\n",
        "figure, ax = plt.subplots(3, 4, figsize=(12, 12))\n",
        "figure.tight_layout()\n",
        "\n",
        "i = 0\n",
        "for R in range(3):\n",
        "    for C in range(4):\n",
        "        # Randomly select a sample from the test dataset\n",
        "        sample_idx = torch.randint(len(test_data), size=(1,)).item()\n",
        "        img, label = test_data[sample_idx]\n",
        "\n",
        "        # Predict the label for the selected sample\n",
        "        img = img.to(device)\n",
        "        output = F.softmax(model(img.unsqueeze(0)), dim=-1)\n",
        "        pred_value, pred_label = output.max(-1)\n",
        "\n",
        "        # # Move the image and label back to the CPU for visualization\n",
        "        # img = img.cpu()\n",
        "        # label = label.cpu()\n",
        "        # pred_label = pred_label.cpu()\n",
        "\n",
        "        # Plot the image\n",
        "        ax[R, C].imshow(torch.clamp(img, min=0, max=1).permute(1, 2, 0), cmap='Greys_r')\n",
        "        ax[R, C].set_title('Actual: ' + str(label), fontsize=16).set_color('k')  # Actual labels\n",
        "        if label == pred_label:\n",
        "            ax[R, C].set_xlabel('Predicted: ' + pred_label, fontsize=16).set_color('b')  # Correct predictions\n",
        "        else:\n",
        "            ax[R, C].set_xlabel('Predicted: ' + str(pred_label.item()), fontsize=16).set_color('r')  # Wrong predictions\n",
        "        ax[R, C].set_ylabel(f'Prob: {pred_value.item():.2f}', fontsize=16, rotation=0, labelpad=30).set_color('m')  # Probability of predicted class\n",
        "        ax[R, C].set_xticks([])\n",
        "        ax[R, C].set_yticks([])\n",
        "        i += 1\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1NE90l4aDPDV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchview\n",
        "from torchview import draw_graph\n",
        "\n",
        "model_graph = draw_graph(model, input_size=(1,3,150,150), expand_nested=True)\n",
        "model_graph.visual_graph\n",
        "model_graph.resize_graph(scale=5.0) # scale as per the view\n",
        "model_graph.visual_graph.render(format='png')"
      ],
      "metadata": {
        "id": "4GrjjQWwhAOY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchviz\n",
        "from torchviz import make_dot\n",
        "\n",
        "input_tensor = torch.randn(1, 3, 150, 150)\n",
        "output_tensor = model(input_tensor)\n",
        "\n",
        "make_dot(output_tensor, params=dict(list(model.named_parameters()))).render(\"architecture\", format=\"png\")"
      ],
      "metadata": {
        "id": "2b6PJgnBhEU4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}